{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n    \\n    X_class, X_family, y_class, y_family = loadDataset(7, feature_scailing=False)\\n    print(X_class.shape)\\n    print(X_family.shape)\\n    print(y_class.shape)\\n    print(y_family.shape)\\n    \\n    X = loadSample()\\n    \\n    result_class = predict_class(X_class, y_class, X)\\n    result_family = predict_family(X_family, y_family, X)\\n    \\n    df = pd.concat([result_class,result_family])\\n    print(df.shape)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python2.7\n",
    "# command\n",
    "# sudo python decompileApk.py /folder\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "smali_1gram_f = \"1st_smali_1gram.csv\"\n",
    "smali_4gram_f = \"1st_smali_4gram.csv\"\n",
    "java_function_f = \"1st_java_function.csv\"\n",
    "permission_f = \"1st_permission.csv\"\n",
    "y_f = \"1st_y.csv\"\n",
    "\n",
    "def decompile(walk_dir, pool=16):\n",
    "        command1 = []\n",
    "        command2 = []\n",
    "        command3 = []\n",
    "\n",
    "    \n",
    "        if walk_dir[-1] is not '/':\n",
    "            walk_dir += '/'\n",
    "\n",
    "        o_dir = walk_dir[:-1] + \"_apktools/\"\n",
    "        os.system('mkdir '+ o_dir)\n",
    "        #-------------------------------------decompile----------------------------\n",
    "        print(\"start decompiling:\", walk_dir)\n",
    "        i = 0\n",
    "        once = True\n",
    "        for root, subdirs, files in os.walk(walk_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".apk\") or file.endswith(\".vir\"):\n",
    "                    i=i+1\n",
    "                    #print(str(i)+\"-\"+file )\n",
    "                    if file.endswith(\".apk\"):\n",
    "                        o_file = root+file\n",
    "                    else :\n",
    "                        o_file = root+file.split('.')[0]+\".apk\"\n",
    "                        os.system(\"mv {} {} \".format(root+file, o_file))\n",
    "\n",
    "                    command1.append(\"apktool d {} -o {} -f > /dev/null\".format(o_file, o_dir+file.split('.')[0]))\n",
    "                    command2.append(\"unzip -n {} -d {} > /dev/null\".format(o_file, o_dir+file.split('.')[0]))\n",
    "                    command3.append('JAVA_OPTS=\"-Xmx16G\" jadx -j 1 -d {} {}'.format(o_dir+file.split('.')[0]+'/out > /dev/null', \n",
    "                                                                                    o_dir+file.split('.')[0]+\"/classes.dex\"))\n",
    "                    \n",
    "        with Pool(pool) as p:\n",
    "            i = 0\n",
    "            len_command = len(command3)\n",
    "            \n",
    "            i = 0\n",
    "            print('[*]start decompile apk to smali')\n",
    "            \n",
    "            for result in p.imap(os.system, command1):\n",
    "                i += 1\n",
    "                if i%10==0:\n",
    "                    print('{}%           \\r'.format(i/len_command))\n",
    "            print('{}%           \\r'.format(i/len_command))\n",
    "               \n",
    "            i = 0\n",
    "            print('[*]start extract classes.dex from apk')\n",
    "            \n",
    "            for result in p.imap(os.system, command2):\n",
    "                i += 1\n",
    "                if i%10==0:\n",
    "                    print('processing: {}%           \\r'.format(i/len_command * 100))\n",
    "            print('processing:{}%           \\r'.format(i/len_command * 100))\n",
    "             \n",
    "            i = 0\n",
    "            print('[*]start decompile dex to java')\n",
    "            \n",
    "            for result in p.imap(os.system, command3):\n",
    "                i += 1\n",
    "                if i%10==0:\n",
    "                    print('processing:{}%           \\r'.format(i/len_command * 100))\n",
    "            print('processing:{}%           \\r'.format(i/len_command * 100))\n",
    "            \n",
    "            \n",
    "\n",
    "def machine_learning_for_class(X_train, X_test, Y_train, Y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, Y_train)\n",
    "    svc_result = svc.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, Y_train)\n",
    "    knn_result = knn.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.svm import LinearSVC\n",
    "    lsvc = LinearSVC()\n",
    "    lsvc.fit(X_train, Y_train)\n",
    "    lsvc_result = lsvc.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    nb_result = clf.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    decision_tree_result = clf.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    random_forest_result = clf.score(X_test,Y_test)\n",
    "    \n",
    "    #nn_result = keras_nn_for_class(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    result = {\n",
    "        'svm_svc' : svc_result,\n",
    "        'knn' : knn_result,\n",
    "        'lsvc' : lsvc_result,\n",
    "        'GaussianNB' : nb_result,\n",
    "        'DecisionTree' : decision_tree_result,\n",
    "        'RandomForest' : random_forest_result#,\n",
    "        #\"nn_result\" : nn_result\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def machine_learning_for_family(X_train, X_test, Y_train, Y_test):\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, Y_train)\n",
    "    knn_result = knn.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    decision_tree_result = clf.score(X_test,Y_test)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    random_forest_result = clf.score(X_test,Y_test)\n",
    "    \n",
    "    #nn_result = keras_nn_for_family(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    result = {\n",
    "        'knn' : knn_result,\n",
    "        'DecisionTree' : decision_tree_result,\n",
    "        'RandomForest' : random_forest_result#,\n",
    "        #\"nn_result\" : nn_result\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def keras_nn_for_class(X_train, X_test, Y_train, Y_test, dropout = 0.5, batch_size = 32):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout\n",
    "    \n",
    "    input_node = X_train.shape[1]\n",
    "    \n",
    "    layer = []\n",
    "    batch_size = 16\n",
    "    \n",
    "    train_generator = generator(X_train, Y_train, batch_size=batch_size)\n",
    "    validation_generator = generator(X_test, Y_test, batch_size=batch_size)\n",
    "    \n",
    "    input_shape =(X_train.shape[1],)  # Trimmed image format\n",
    "    #print(\"input_shape:\", input_shape)\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Dense(input_node, activation='relu', input_shape=input_shape , kernel_initializer='normal'))\n",
    "    layer.append(input_node)\n",
    "    model.add(Dropout(dropout)) # for preventing overfit\n",
    "    layer.append(\"Dropout\")\n",
    "    input_node = input_node//2\n",
    "    \n",
    "    \n",
    "    while(input_node > 1):\n",
    "        model.add(Dense(input_node, activation='relu',  kernel_initializer='normal'))\n",
    "        layer.append(input_node)\n",
    "        model.add(Dropout(dropout)) # for preventing overfit\n",
    "        layer.append(\"Dropout\")\n",
    "        input_node = input_node//2\n",
    "        \n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "    layer.append(1)\n",
    "    #print('layer:', layer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #########################################################################\n",
    "    # train a model\n",
    "\n",
    "    history_object = model.fit_generator(train_generator, steps_per_epoch=len(X_train)/batch_size,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(X_test)/batch_size, epochs=10,verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate_generator(validation_generator, steps=len(X_test)/batch_size, max_queue_size=10, workers=1, use_multiprocessing=True)\n",
    "    return score\n",
    "\n",
    "def generator(X, y, batch_size=32):\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    \n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_X = X[offset:offset+batch_size]\n",
    "            batch_y = y[offset:offset+batch_size]\n",
    "        \n",
    "            yield shuffle(batch_X, batch_y)\n",
    "\n",
    "def keras_nn_for_family(X_train, X_test, Y_train, Y_test, dropout = 0.5, batch_size = 32):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout\n",
    "    \n",
    "    input_node = X_train.shape[1]\n",
    "    layer = []\n",
    "    \n",
    "    \n",
    "    train_generator = generator(X_train, Y_train, batch_size=batch_size)\n",
    "    validation_generator = generator(X_test, Y_test, batch_size=batch_size)\n",
    "    \n",
    "    input_shape =(X_train.shape[1],)  # Trimmed image format\n",
    "    #print(\"input_shape:\", input_shape)\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Dense(input_node, activation='relu', input_shape=input_shape , kernel_initializer='normal'))\n",
    "    layer.append(input_node)\n",
    "    model.add(Dropout(dropout)) # for preventing overfit\n",
    "    layer.append(\"Dropout\")\n",
    "    input_node = input_node//2\n",
    "    \n",
    "    \n",
    "    while(input_node > 10):\n",
    "        model.add(Dense(input_node, activation='relu',  kernel_initializer='normal'))\n",
    "        layer.append(input_node)\n",
    "        model.add(Dropout(dropout)) # for preventing overfit\n",
    "        layer.append(\"Dropout\")\n",
    "        input_node = input_node//2\n",
    "        \n",
    "        \n",
    "    model.add(Dense(10, activation='softmax', kernel_initializer='normal'))\n",
    "    layer.append(10)\n",
    "    #print('layer:', layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #########################################################################\n",
    "    # train a model\n",
    "\n",
    "    history_object = model.fit_generator(train_generator, steps_per_epoch=len(X_train)/batch_size,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(X_test)/batch_size, epochs=10, verbose=0)\n",
    "    \n",
    "    loss, score = model.evaluate_generator(validation_generator, steps=len(X_test)/batch_size, max_queue_size=10, workers=1, use_multiprocessing=True)\n",
    "    return score\n",
    "\n",
    "def generator(X, y, batch_size=32):\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    \n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_X = X[offset:offset+batch_size]\n",
    "            batch_y = y[offset:offset+batch_size]\n",
    "        \n",
    "            yield shuffle(batch_X, batch_y)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def loadDataset(X=0, feature_scailing=True):\n",
    "    \n",
    "    if X not in [1,2,3,4,5,6,7]:\n",
    "        \n",
    "        message = '''\\\n",
    "please insert number to X:\n",
    "    if X == 1:\n",
    "        X = ['java']\n",
    "    elif X == 2:\n",
    "        X = ['smali']\n",
    "    elif X == 3:\n",
    "        X = ['permission']\n",
    "    elif X == 4:\n",
    "        X = ['permission', 'java']\n",
    "    elif X == 5:\n",
    "        X = ['permission', 'smali']\n",
    "    elif X == 6:\n",
    "        X = ['java', 'smali']\n",
    "    elif X == 7:\n",
    "        X = ['permission', 'java', 'smali']'''\n",
    "        print(message)\n",
    "        return False\n",
    "    \n",
    "    database = []\n",
    "    \n",
    "    if X == 1:\n",
    "        X = ['java']\n",
    "    elif X == 2:\n",
    "        X = ['smali']\n",
    "    elif X == 3:\n",
    "        X = ['permission']\n",
    "    elif X == 4:\n",
    "        X = ['permission', 'java']\n",
    "    elif X == 5:\n",
    "        X = ['permission', 'smali']\n",
    "    elif X == 6:\n",
    "        X = ['java', 'smali']\n",
    "    elif X == 7:\n",
    "        X = ['permission', 'java', 'smali']\n",
    "    \n",
    "    \n",
    "    #######################\n",
    "    # Y\n",
    "    Y = pd.read_csv('1st_y.csv')\n",
    "    Y.index = Y['filename']\n",
    "    del Y['filename']\n",
    "    Y = Y.sort_index()\n",
    "    Y = Y.fillna(0)\n",
    "    Y_class = Y['class']\n",
    "    Y_fam = Y[Y['class']==1].drop(['class'],axis=1)\n",
    "    \n",
    "    if 'permission' in X:\n",
    "        ######################\n",
    "        # Permissions\n",
    "        premissions_X = pd.read_csv(permission_f)\n",
    "        premissions_X.index = premissions_X['Unnamed: 0']\n",
    "        del premissions_X['Unnamed: 0']\n",
    "        premissions_X = premissions_X.sort_index()\n",
    "        premissions_X = premissions_X.fillna(0)\n",
    "        database.append(premissions_X)\n",
    "        \n",
    "    if 'java' in X:\n",
    "        ##############################\n",
    "        # java function\n",
    "        java_X = pd.read_csv(java_function_f)\n",
    "        java_X.index = java_X['Unnamed: 0']\n",
    "        del java_X['Unnamed: 0']\n",
    "        java_X = java_X.sort_index()\n",
    "        java_X = java_X.fillna(0)\n",
    "        database.append(java_X)\n",
    "    \n",
    "    if 'smali' in X:\n",
    "        ##############################\n",
    "        # smali 4gram\n",
    "        #smali_X = pd.read_csv(\"bm_df_smali_4gram_X.csv\")\n",
    "        #smali_X.index = smali_X['Unnamed: 0']\n",
    "        #del smali_X['Unnamed: 0']\n",
    "        #smali_X = smali_X.sort_index()\n",
    "        #smali_X = smali_X.fillna(0)\n",
    "        #database.append(smali_X)\n",
    "        \n",
    "        ##############################\n",
    "        # smali one word function\n",
    "        smali_X_1 = pd.read_csv(smali_1gram_f)\n",
    "        smali_X_1.index = smali_X_1['Unnamed: 0']\n",
    "        del smali_X_1['Unnamed: 0']\n",
    "        smali_X_1 = smali_X_1.sort_index()\n",
    "        smali_X_1 = smali_X_1.fillna(0).T\n",
    "        database.append(smali_X_1)\n",
    "\n",
    "    X_class = pd.concat(database, axis=1).fillna(0)\n",
    "    X_family = X_class.loc[Y_fam.index].fillna(0)\n",
    "    Y_class = Y_class.loc[X_class.index].fillna(0)\n",
    "    Y_fam = Y_fam.loc[X_family.index].fillna(0)\n",
    "\n",
    "    \n",
    "    if feature_scailing:\n",
    "        # Feature scailing\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc_X = StandardScaler()\n",
    "        X_class = sc_X.fit_transform(X_class.values)\n",
    "        sc_X = StandardScaler()\n",
    "        X_family = sc_X.fit_transform(X_family.values)\n",
    "        \n",
    "    return X_class, X_family, Y_class, Y_fam\n",
    "\n",
    "def predict_class(X_class, Y_class, X):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_class = sc_X.fit_transform(X_class.values)\n",
    "    X = sc_X.transform(X.values)\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    #from sklearn.ensemble import RandomForestClassifier\n",
    "    #clf = RandomForestClassifier()\n",
    "    clf.fit(X_class, Y_class)\n",
    "    decision_tree_result = clf.predict(X)\n",
    "    return decision_tree_result\n",
    "\n",
    "def predict_family(X_family, Y_family, X):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_family = sc_X.fit_transform(X_family.values)\n",
    "    X = sc_X.transform(X.values)\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_family, Y_family)\n",
    "    decision_tree_result = clf.predict(X)\n",
    "    return decision_tree_result\n",
    "\n",
    "def loadSample(X=7):\n",
    "    \n",
    "    database = []\n",
    "    smali_1gram_f = \"2nd_smali_1gram.csv\"\n",
    "    smali_4gram_f = \"2nd_smali_4gram.csv\"\n",
    "    java_function_f = \"2nd_java_function.csv\"\n",
    "    permission_f = \"2nd_permission.csv\"\n",
    "    \n",
    "    if X == 1:\n",
    "        X = ['java']\n",
    "    elif X == 2:\n",
    "        X = ['smali']\n",
    "    elif X == 3:\n",
    "        X = ['permission']\n",
    "    elif X == 4:\n",
    "        X = ['permission', 'java']\n",
    "    elif X == 5:\n",
    "        X = ['permission', 'smali']\n",
    "    elif X == 6:\n",
    "        X = ['java', 'smali']\n",
    "    elif X == 7:\n",
    "        X = ['permission', 'java', 'smali']\n",
    "    \n",
    "    if 'permission' in X:\n",
    "        ######################\n",
    "        # Permissions\n",
    "        premissions_X = pd.read_csv(permission_f)\n",
    "        premissions_X.index = premissions_X['Unnamed: 0']\n",
    "        del premissions_X['Unnamed: 0']\n",
    "        premissions_X = premissions_X.sort_index()\n",
    "        premissions_X = premissions_X.fillna(0)\n",
    "        database.append(premissions_X)\n",
    "        \n",
    "    if 'java' in X:\n",
    "        ##############################\n",
    "        # java function\n",
    "        java_X = pd.read_csv(java_function_f)\n",
    "        java_X.index = java_X['Unnamed: 0']\n",
    "        del java_X['Unnamed: 0']\n",
    "        java_X = java_X.sort_index()\n",
    "        java_X = java_X.fillna(0)\n",
    "        database.append(java_X)\n",
    "    \n",
    "    if 'smali' in X:\n",
    "        ##############################\n",
    "        # smali 4gram\n",
    "        #smali_X = pd.read_csv(\"bm_df_smali_4gram_X.csv\")\n",
    "        #smali_X.index = smali_X['Unnamed: 0']\n",
    "        #del smali_X['Unnamed: 0']\n",
    "        #smali_X = smali_X.sort_index()\n",
    "        #smali_X = smali_X.fillna(0)\n",
    "        #database.append(smali_X)\n",
    "        \n",
    "        ##############################\n",
    "        # smali one word function\n",
    "        smali_X_1 = pd.read_csv(smali_1gram_f)\n",
    "        smali_X_1.index = smali_X_1['Unnamed: 0']\n",
    "        del smali_X_1['Unnamed: 0']\n",
    "        smali_X_1 = smali_X_1.sort_index()\n",
    "        smali_X_1 = smali_X_1.fillna(0)\n",
    "        database.append(smali_X_1)\n",
    "\n",
    "    X_class = pd.concat(database, axis=1).fillna(0)\n",
    "    \n",
    "    return X_class\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    X_class, X_family, y_class, y_family = loadDataset(7, feature_scailing=False)\n",
    "    print(X_class.shape)\n",
    "    print(X_family.shape)\n",
    "    print(y_class.shape)\n",
    "    print(y_family.shape)\n",
    "    \n",
    "    X = loadSample()\n",
    "    \n",
    "    result_class = predict_class(X_class, y_class, X)\n",
    "    result_family = predict_family(X_family, y_family, X)\n",
    "    \n",
    "    df = pd.concat([result_class,result_family])\n",
    "    print(df.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Loading Dataset...\n",
      "(2000, 2080)\n",
      "(500, 2080)\n",
      "(2000,)\n",
      "(500, 10)\n",
      "[*]Loading Samples...\n",
      "X.shape: (2000, 2080)\n",
      "[*]Training and Predicting Samples about class...\n",
      "[*]done! malware count: 507\n",
      "[*]Training and Predicting Samples about family...\n",
      "[*]done! malware count: \n",
      "family_adwo            49.0\n",
      "family_airpush         40.0\n",
      "family_boxer           48.0\n",
      "family_counterclank    53.0\n",
      "family_dowgin          67.0\n",
      "family_gappusin        43.0\n",
      "family_opfake          53.0\n",
      "family_smsagent        49.0\n",
      "family_smstado         57.0\n",
      "family_wapsx           48.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"[*]Loading Dataset...\")\n",
    "X_class, X_family, y_class, y_family = loadDataset(4, feature_scailing=False)\n",
    "print(X_class.shape)\n",
    "print(X_family.shape)\n",
    "print(y_class.shape)\n",
    "print(y_family.shape)\n",
    "\n",
    "print(\"[*]Loading Samples...\")\n",
    "X = loadSample(4)\n",
    "print(\"X.shape:\",X.shape)\n",
    "\n",
    "print(\"[*]Training and Predicting Samples about class...\")\n",
    "result_class = predict_class(X_class, y_class, X)\n",
    "result_class = pd.Series(result_class, index = X.index, name=\"class\")\n",
    "malware_list = result_class[result_class==1].index\n",
    "print(\"[*]done! malware count: {}\".format(len(malware_list)))\n",
    "\n",
    "\n",
    "print(\"[*]Training and Predicting Samples about family...\")\n",
    "result_family = predict_family(X_family, y_family, X.loc[malware_list])\n",
    "result_family = pd.DataFrame(result_family, index = malware_list, columns=y_family.columns)\n",
    "print(\"[*]done! malware count: \\n{}\".format(result_family.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['family_adwo', 'family_airpush', 'family_boxer', 'family_counterclank',\n",
       "       'family_dowgin', 'family_gappusin', 'family_opfake', 'family_smsagent',\n",
       "       'family_smstado', 'family_wapsx'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_family.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000ef8ee5e09458686ca98ac8914eafdc0e5e937ae2bcac90ce591a4ad22d023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001652ebc24cc76dbe3fb27d80eb137fa8b60832958ace7617c6d0c6fdb6d18a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00d56ee88d368ea75997bce26cd5c90a2d0be8981d355c82acf053768bad43f0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00d7f6f13d72210c232707853f28ca2f0267ccab605e7366c92e336faf6bf6bc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00e5635e0af8a17aca2e22f3fcbd52314c0aa16012ec7af30a31a42aea1dcfe8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00f130be2d96cb994c0b7465d6392b30675a8a1186688ef053e1a0c0b0be25dc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>adwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>012bfafab8a84bdeb62a22af97ccafaec924cef3329680787dad16dbb2992ca1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0160c026ef59c9c0fe74cfb26082858ce4def298114ef904ad50b8d56a7f8b50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01718bfe393c5235cdb559eafe1bc3921238e063c087881fed2fe3db187c4b5e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0178c9d429db092f01bfd5c920be9b2f18791d3b69b4a12eaffdd6e59094bff0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01a3420d3b50210dd401164ea00a6598348b1b51e64f314e9afe2d15c347db4d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01c21bd5f65c682f84c036488b30dca7a4ccbf5d34bf12b151d650373f8adce4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01ddd3d15fe5bf13507d39694f572ee204e9bae82fa3607c780ea7e24491ab26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01f23cfb8a85f73e5de41afda87f6146a168e4d647def9d78c169130c32d3b94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>023187446528684cea9b98fdb17edb08839e4afaf35deb11e0c086a3edad79ee</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>024e335915472925e5747006677ec01a7874e9775a76d7bf734480093cd1e8ec</th>\n",
       "      <td>1.0</td>\n",
       "      <td>adwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025360a8bd92f852bf30fce7d583cc7d3add7f2a63b46409ad55b4ff962d20a9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02ca4a1852fa6ec4714f1c34593b2e1e8ca713057332cd4bd71c3bfb64dc418c</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>030015200bbc4dea8def1b73df5c60237bba90776766768867b235cdad9dbaac</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0308371d4e5066ea9bd8bbe42373794a2df56f37b60b75bdc2ff7139af9af75a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>032985630ca8950ff97c8f09ade7b441257d827d02730638e5ca18aada438e5f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033156a360ee173e75733312975f7fa419ea3f6f0d93a2337fda3dc28dd2b9dd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>036093a42905886495109281fcc5b72b46809b0bcf4a4d1b9712370012ce5071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>037dd4cb560d886e36b57011835964d93884e68a822217c7024d697ad399611d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>037fb61166869832ccd1a7de2b4744c9836191337ae770c85abccc99e3207bf8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03d3787ea188922e720182c80c5004a26a2762a4acda61a974ed7e658e821fcc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03e51cb7571b3c7da1f063d69dcba6e29c2aaa2dfeec2e056a9f0f6df3fddf8e</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>040f42c6ea0b06e142c5b4cd815078fb4ddf1216cc38d24f6b5889c7ae6a2e24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>043964a7818aca1b72af12e7d5373eed492c21ecc7fa59a13484fe12a4d4f517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0471e710fd77b4d1515f5b18c024e9b6c9174261a3bfc699a2e81298e47eb019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa966322ed5e02a0e467f90f01815c1bc4bca689b68a6f2ee0c3efa4479c16db</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fad7bf53e398564d263b7917c7ea69731447c17c46693f46ce5c5f1ba06c5507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fae0ab47b139d927a7f30fcb32d4c62d16bd5225541cc4e34584de90e6e79eab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faf4c35d764e5ee6c6544aebc3789c7ba0c19c2f2384fe3e203ed0379ba69083</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb221f4f9ad9ec4deac3288228c66d5ff3b36e58f072413f10afb09201a49d87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb2ac3df254b13ce826c8f2d2236f298185c310a71e3755bf63bc23381ed5ee9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb43d9364bcc962e247b6f347446e25c65a14a93c1d62b40cfb78d7b63cf4f6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb6993f4b2593d84f6a1d312c4271047e4ef6dac7b1f873cdc87f2874c42a7e4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb6f0bde9474e4e20b7516cf0675135ed902781a37a247bf3a59726bd295cb36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbc8d3d66498a11d43fa0f60b7374e7bac6661283494687f6918aea3d0942dac</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbff7e4056d84bb8917bf9b6785647ee74baa93da714d54291aca5a41c967a39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc46448f37209e9ba2f0809b5bc3bab0ed6a88a0f63b0913aaf6abb7472594c8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc5291382d593b19d83ec2c795b711554df718b980581b02afe75cdd5cb8b6c2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc6b73c19b37c9d444d38c1b8dbd800513b8843b0f1def678748c10baa26b543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc6cedd832d2066957f23760c00974c77433a07ce8d22bdbf5d973fc2303512d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcbb2264165101a0ec374a32d32c6d9d3cee6047f1d001a1898a978ac5a37167</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fced6f6b1a0b43040dc0a5c59759efad5a004042f95d84264836dd7c04414613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd0d4ce9cbe4d64129fe561174d88ed18cf4985f7f168ace48bc567c6e30fb4f</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd3d6c9808b5dd7427a85c74657062391475c1420707aeb86638c6e2733e5ee3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd5666ea1aab77014c942e9d041e753f713d6c60f508fb8d5aba276cd15ba482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd8f418034de9007f6f636dbd961b3746aa360b2d801a281b803ed2d342e7df2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdd3914d5fc6027178b777032931408226f90c373c2fec2333d1e1cc318d9f4d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdf40e1207d4e8701228ae1e7e14e87b6ae86a6b3fcf1eaf69d9937cc090e0df</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe05d27ea5e730e08c296e22daf752c88e47bbc1d46e0094ac14ebc7ab290c93</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fec3bcd6747e63495b5a1ea657d3a81f6381d9abe0f12bdff49f42a7c555f186</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fece62762bff385172719d0f14c09bb6c5261aacd286d16f53a741aeba55e892</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fedbd0d1998bec7e4353915662ac23aa8af1871096e5d250a4f40516f41e7901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fefcd51848ebcb12ab075eb031888e2c42171f488544c285ee8c5a2ed57fb9af</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff1e35e784727fe95f148d965c659251c5c8f5a2f134e2b06353e0a03b2806eb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff280cabf75d279695720cda9f9d3c1c8df31bad3b209fb69bf31b6798712fd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    class family\n",
       "000ef8ee5e09458686ca98ac8914eafdc0e5e937ae2bcac...    0.0    NaN\n",
       "001652ebc24cc76dbe3fb27d80eb137fa8b60832958ace7...    1.0    NaN\n",
       "00d56ee88d368ea75997bce26cd5c90a2d0be8981d355c8...    0.0    NaN\n",
       "00d7f6f13d72210c232707853f28ca2f0267ccab605e736...    0.0    NaN\n",
       "00e5635e0af8a17aca2e22f3fcbd52314c0aa16012ec7af...    0.0    NaN\n",
       "00f130be2d96cb994c0b7465d6392b30675a8a1186688ef...    1.0   adwo\n",
       "012bfafab8a84bdeb62a22af97ccafaec924cef33296807...    0.0    NaN\n",
       "0160c026ef59c9c0fe74cfb26082858ce4def298114ef90...    0.0    NaN\n",
       "01718bfe393c5235cdb559eafe1bc3921238e063c087881...    0.0    NaN\n",
       "0178c9d429db092f01bfd5c920be9b2f18791d3b69b4a12...    0.0    NaN\n",
       "01a3420d3b50210dd401164ea00a6598348b1b51e64f314...    0.0    NaN\n",
       "01c21bd5f65c682f84c036488b30dca7a4ccbf5d34bf12b...    0.0    NaN\n",
       "01ddd3d15fe5bf13507d39694f572ee204e9bae82fa3607...    0.0    NaN\n",
       "01f23cfb8a85f73e5de41afda87f6146a168e4d647def9d...    0.0    NaN\n",
       "023187446528684cea9b98fdb17edb08839e4afaf35deb1...    1.0    NaN\n",
       "024e335915472925e5747006677ec01a7874e9775a76d7b...    1.0   adwo\n",
       "025360a8bd92f852bf30fce7d583cc7d3add7f2a63b4640...    0.0    NaN\n",
       "02ca4a1852fa6ec4714f1c34593b2e1e8ca713057332cd4...    1.0    NaN\n",
       "030015200bbc4dea8def1b73df5c60237bba90776766768...    0.0    NaN\n",
       "0308371d4e5066ea9bd8bbe42373794a2df56f37b60b75b...    0.0    NaN\n",
       "032985630ca8950ff97c8f09ade7b441257d827d0273063...    0.0    NaN\n",
       "033156a360ee173e75733312975f7fa419ea3f6f0d93a23...    1.0    NaN\n",
       "036093a42905886495109281fcc5b72b46809b0bcf4a4d1...    0.0    NaN\n",
       "037dd4cb560d886e36b57011835964d93884e68a822217c...    0.0    NaN\n",
       "037fb61166869832ccd1a7de2b4744c9836191337ae770c...    0.0    NaN\n",
       "03d3787ea188922e720182c80c5004a26a2762a4acda61a...    0.0    NaN\n",
       "03e51cb7571b3c7da1f063d69dcba6e29c2aaa2dfeec2e0...    1.0    NaN\n",
       "040f42c6ea0b06e142c5b4cd815078fb4ddf1216cc38d24...    1.0    NaN\n",
       "043964a7818aca1b72af12e7d5373eed492c21ecc7fa59a...    1.0    NaN\n",
       "0471e710fd77b4d1515f5b18c024e9b6c9174261a3bfc69...    0.0    NaN\n",
       "...                                                   ...    ...\n",
       "fa966322ed5e02a0e467f90f01815c1bc4bca689b68a6f2...    0.0    NaN\n",
       "fad7bf53e398564d263b7917c7ea69731447c17c46693f4...    0.0    NaN\n",
       "fae0ab47b139d927a7f30fcb32d4c62d16bd5225541cc4e...    0.0    NaN\n",
       "faf4c35d764e5ee6c6544aebc3789c7ba0c19c2f2384fe3...    0.0    NaN\n",
       "fb221f4f9ad9ec4deac3288228c66d5ff3b36e58f072413...    0.0    NaN\n",
       "fb2ac3df254b13ce826c8f2d2236f298185c310a71e3755...    0.0    NaN\n",
       "fb43d9364bcc962e247b6f347446e25c65a14a93c1d62b4...    0.0    NaN\n",
       "fb6993f4b2593d84f6a1d312c4271047e4ef6dac7b1f873...    0.0    NaN\n",
       "fb6f0bde9474e4e20b7516cf0675135ed902781a37a247b...    0.0    NaN\n",
       "fbc8d3d66498a11d43fa0f60b7374e7bac6661283494687...    1.0    NaN\n",
       "fbff7e4056d84bb8917bf9b6785647ee74baa93da714d54...    1.0    NaN\n",
       "fc46448f37209e9ba2f0809b5bc3bab0ed6a88a0f63b091...    0.0    NaN\n",
       "fc5291382d593b19d83ec2c795b711554df718b980581b0...    1.0    NaN\n",
       "fc6b73c19b37c9d444d38c1b8dbd800513b8843b0f1def6...    0.0    NaN\n",
       "fc6cedd832d2066957f23760c00974c77433a07ce8d22bd...    0.0    NaN\n",
       "fcbb2264165101a0ec374a32d32c6d9d3cee6047f1d001a...    0.0    NaN\n",
       "fced6f6b1a0b43040dc0a5c59759efad5a004042f95d842...    1.0    NaN\n",
       "fd0d4ce9cbe4d64129fe561174d88ed18cf4985f7f168ac...    1.0    NaN\n",
       "fd3d6c9808b5dd7427a85c74657062391475c1420707aeb...    0.0    NaN\n",
       "fd5666ea1aab77014c942e9d041e753f713d6c60f508fb8...    0.0    NaN\n",
       "fd8f418034de9007f6f636dbd961b3746aa360b2d801a28...    0.0    NaN\n",
       "fdd3914d5fc6027178b777032931408226f90c373c2fec2...    0.0    NaN\n",
       "fdf40e1207d4e8701228ae1e7e14e87b6ae86a6b3fcf1ea...    0.0    NaN\n",
       "fe05d27ea5e730e08c296e22daf752c88e47bbc1d46e009...    1.0    NaN\n",
       "fec3bcd6747e63495b5a1ea657d3a81f6381d9abe0f12bd...    1.0    NaN\n",
       "fece62762bff385172719d0f14c09bb6c5261aacd286d16...    0.0    NaN\n",
       "fedbd0d1998bec7e4353915662ac23aa8af1871096e5d25...    0.0    NaN\n",
       "fefcd51848ebcb12ab075eb031888e2c42171f488544c28...    0.0    NaN\n",
       "ff1e35e784727fe95f148d965c659251c5c8f5a2f134e2b...    0.0    NaN\n",
       "fff280cabf75d279695720cda9f9d3c1c8df31bad3b209f...    0.0    NaN\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_family(row):\n",
    "    for c in result_family.columns:\n",
    "        if row[c]==1:\n",
    "            return c.split(\"_\")[1]\n",
    "        else :\n",
    "            return np.nan\n",
    "        \n",
    "result_family = result_family.apply(get_family, axis=1)\n",
    "result_family.name = \"family\"\n",
    "df = pd.concat([result_class,result_family], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"result_andro_IlsunChoi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
